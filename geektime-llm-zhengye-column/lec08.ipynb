{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNw6BWoZsxn2131ovlMVuXE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install -Uqq langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6bPaz4Wn-SO",
        "outputId": "be0ed624-04ee-43f2-a5a3-d5e433c04dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_community.chat_models import ChatPerplexity\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "NdgR85ARn4OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into Chinese:\"),\n",
        "    HumanMessage(content=\"Welcome to LLM application development!\"),\n",
        "]\n",
        "\n",
        "model = ChatPerplexity(\n",
        "    temperature=0, pplx_api_key=userdata.get('pplx_api_key'), model=\"llama-3.1-8b-instruct\"\n",
        ")\n",
        "\n",
        "result = model.invoke(messages)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RteNN5LJoujg",
        "outputId": "ed6823fd-4fb2-4e09-d837-98319c877259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='欢迎来到LLM应用开发！' additional_kwargs={} response_metadata={} id='run-ef8d8875-264c-41f3-91cc-2e05e7bcc688-0'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stream = model.stream(messages)\n",
        "for response in stream:\n",
        "    print(response.content, end=\"|\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PtsIX73nlH5",
        "outputId": "49542c17-e4f7-44ab-da51-7e6146355cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "欢|迎来|到LL|M应用|开发！||"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"Translate the following from English into Chinese:\"),\n",
        "        (\"user\", \"{text}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt_template | model\n",
        "result = chain.invoke({\"text\":\"Welcome to LLM application development!\"})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz9Q4szGqeZT",
        "outputId": "5fbe904b-adcc-4ce6-a830-2b81a0fb888e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='欢迎来到LLM应用开发！' additional_kwargs={} response_metadata={} id='run-63c5301e-5cf5-40ef-9527-a5579562181d-0'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = prompt_template.invoke({\"text\":\"Welcome to LLM application development!\"})\n",
        "print(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UORtqq_7rn1l",
        "outputId": "aedd56cc-fdce-4f32-afe2-80b6ce36a1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "messages=[SystemMessage(content='Translate the following from English into Chinese:', additional_kwargs={}, response_metadata={}), HumanMessage(content='Welcome to LLM application development!', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"Translate the following from English into Chinese:\"),\n",
        "        (\"user\", \"{text}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "chain = prompt_template | model | parser\n",
        "result = chain.invoke({\"text\":\"Welcome to LLM application development!\"})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4YoV38zr0fq",
        "outputId": "a2f63d9c-83c3-44d2-fdee-05d23fc3e18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "欢迎来到LLM应用开发！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatPerplexity(\n",
        "    temperature=0, pplx_api_key=userdata.get('pplx_api_key'), model=\"llama-3.1-sonar-huge-128k-online\"\n",
        ")"
      ],
      "metadata": {
        "id": "6QB3tPGsS2ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Work(BaseModel):\n",
        "    title: str = Field(description=\"Title of the work\")\n",
        "    description: str = Field(description=\"Description of the work\")\n",
        "\n",
        "\n",
        "parser = JsonOutputParser(pydantic_object=Work)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"列举3部{author}的作品。\\n{format_instructions}\",\n",
        "    input_variables=[\"author\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "chain = prompt | model | parser\n",
        "result = chain.invoke({\"author\": \"老舍\"})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_Gh5tTfsGyR",
        "outputId": "330a5e1e-4dc2-4db4-8e8f-c91c8709c831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'title': '骆驼祥子', 'description': '老舍笔下的祥子来自乡间，带着中国农村破败凋敝的大背景，也带着农民的质朴和固执。当他认准了拉车这一行，他就成了车迷，一心想买上自己拉车的骆驼。'}, {'title': '茶馆', 'description': '这部话剧真实地记述了北平沦陷后的畸形世态，形象地描摹了日寇侵占下的北京市民的生活和思想。'}, {'title': '四世同堂', 'description': '作品以祁家四世同堂的生活为主线，辅以小学圈胡同各色人等的荣辱浮沉、生死存亡，真实地记述了北平沦陷后的畸形世态。'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = prompt.invoke({\"author\": \"老舍\"})\n",
        "print(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcXhj74rsctD",
        "outputId": "a0be2aac-5474-4a49-bff9-36e202741e58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text='列举3部老舍的作品。\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"title\": {\"description\": \"Title of the work\", \"title\": \"Title\", \"type\": \"string\"}, \"description\": {\"description\": \"Description of the work\", \"title\": \"Description\", \"type\": \"string\"}}, \"required\": [\"title\", \"description\"]}\\n```'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QJorr8L3Sdlp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}