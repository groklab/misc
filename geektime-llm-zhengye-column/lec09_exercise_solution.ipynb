{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0NQRtca/AEibz5oeAKl3E"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 09 从零实现一个角色扮演的聊天机器人"
      ],
      "metadata": {
        "id": "EiowGDxySu9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -Uqq langchain-xai"
      ],
      "metadata": {
        "id": "vRovHIcLufzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_xai import ChatXAI\n",
        "\n",
        "chat_model = ChatXAI(\n",
        "    xai_api_key=userdata.get('xai_api_key'),\n",
        "    model=\"grok-beta\",\n",
        ")"
      ],
      "metadata": {
        "id": "00IMxXgOxL5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables import RunnableWithMessageHistory\n",
        "import json\n",
        "import os\n",
        "from typing import List\n",
        "import tiktoken\n",
        "from langchain_core.messages import SystemMessage, trim_messages, BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "def str_token_counter(text: str) -> int:\n",
        "    enc = tiktoken.get_encoding(\"o200k_base\")\n",
        "    return len(enc.encode(text))\n",
        "\n",
        "def tiktoken_counter(messages: List[BaseMessage]) -> int:\n",
        "    num_tokens = 3\n",
        "    tokens_per_message = 3\n",
        "    tokens_per_name = 1\n",
        "    for msg in messages:\n",
        "        if isinstance(msg, HumanMessage):\n",
        "            role = \"user\"\n",
        "        elif isinstance(msg, AIMessage):\n",
        "            role = \"assistant\"\n",
        "        elif isinstance(msg, ToolMessage):\n",
        "            role = \"tool\"\n",
        "        elif isinstance(msg, SystemMessage):\n",
        "            role = \"system\"\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported messages type {msg.__class__}\")\n",
        "        num_tokens += (\n",
        "                tokens_per_message\n",
        "                + str_token_counter(role)\n",
        "                + str_token_counter(msg.content)\n",
        "        )\n",
        "        if msg.name:\n",
        "            num_tokens += tokens_per_name + str_token_counter(msg.name)\n",
        "    return num_tokens\n",
        "\n",
        "trimmer = trim_messages(\n",
        "    max_tokens=4096,\n",
        "    strategy=\"last\",\n",
        "    token_counter=tiktoken_counter,\n",
        "    include_system=True,\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"你现在扮演孔子的角色，尽量按照孔子的风格回复，不要出现‘子曰’\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 文件持久化历史记录类\n",
        "class FileChatMessageHistory(BaseChatMessageHistory):\n",
        "    def __init__(self, session_id: str, file_path: str = \"chat_histories\"):\n",
        "        super().__init__()\n",
        "        self.session_id = session_id\n",
        "        os.makedirs(file_path, exist_ok=True)\n",
        "        self.file_path = os.path.join(file_path, f\"{session_id}.json\")\n",
        "        self.messages = self._load_messages()\n",
        "\n",
        "    def _load_messages(self):\n",
        "        if not os.path.exists(self.file_path):\n",
        "            return []\n",
        "        try:\n",
        "            with open(self.file_path, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "                return [\n",
        "                    HumanMessage(content=msg['content']) if msg['type'] == 'human'\n",
        "                    else AIMessage(content=msg['content'])\n",
        "                    for msg in data\n",
        "                ]\n",
        "        except Exception as e:\n",
        "            print(f\"加载历史消息时出错: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def _save_messages(self):\n",
        "        try:\n",
        "            data = [\n",
        "                {\n",
        "                    'type': 'human' if isinstance(msg, HumanMessage) else 'ai',\n",
        "                    'content': msg.content\n",
        "                }\n",
        "                for msg in self.messages\n",
        "            ]\n",
        "            with open(self.file_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "        except Exception as e:\n",
        "            print(f\"保存消息时出错: {str(e)}\")\n",
        "\n",
        "    def add_message(self, message):\n",
        "        self.messages.append(message)\n",
        "        self._save_messages()\n",
        "\n",
        "    def clear(self):\n",
        "        self.messages = []\n",
        "        if os.path.exists(self.file_path):\n",
        "            os.remove(self.file_path)\n",
        "\n",
        "session_histories = {}\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in session_histories:\n",
        "        session_histories[session_id] = FileChatMessageHistory(session_id=session_id)\n",
        "    return session_histories[session_id]\n",
        "\n",
        "with_message_history = RunnableWithMessageHistory(\n",
        "    trimmer | prompt | chat_model,\n",
        "    get_session_history,\n",
        ")\n",
        "\n",
        "config = {\"configurable\": {\"session_id\": \"confucious\"}}\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You:> \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "    stream = with_message_history.stream(\n",
        "        {\"messages\": [HumanMessage(content=user_input)]},\n",
        "        config=config\n",
        "    )\n",
        "    for chunk in stream:\n",
        "        print(chunk.content, end='', flush=True)\n",
        "    print()"
      ],
      "metadata": {
        "id": "ysi6mYy34jLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3fdZ_Gor4wuP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}